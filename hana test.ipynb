{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82183dc6-3a51-40f5-b086-f653c981966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('classification_dat.pkl', 'rb') as f:  # open a text file\n",
    "    classification_df = pickle.load(f)\n",
    "\n",
    "with open('regression_dat.pkl', 'rb') as f:  # open a text file\n",
    "    regression_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81156182-7bbc-479e-b0cd-633781947736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import dataframe\n",
    "\n",
    "config = 'hana-build.hana-ml.c.ap-cn-1.cloud.sap', 31315, 'xxxxx', 'xxxxx'\n",
    "connection_context = dataframe.ConnectionContext(address=config[0], port=config[1], user=config[2], password=config[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9918c-f186-4581-8019-4b678f3aea7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress Indicator Id:  AutoML-7CF4CC7D_B8D2_11EE_B545_F47B099F40D8\n",
      "Creation Time:  2024-01-22 03:01:15.600000\n",
      "Function Name:  AUTOML_FIT\n",
      "+---------+-----------------+-------------------+--------------------+----------+\n",
      "|  Status | Pipeline Number | Generation Number | Current Generation | Progress |\n",
      "+---------+-----------------+-------------------+--------------------+----------+\n",
      "| Running |        62       |         5         |   Initialization   |   0 %    |\n",
      "+---------+-----------------+-------------------+--------------------+----------+\n",
      "\n",
      "Current Generation Details:  Initialization\n",
      "+------------+-----------+-----------+--------+---------+\n",
      "| Evaluating | Evaluated | Succeeded | Failed | Timeout |\n",
      "+------------+-----------+-----------+--------+---------+\n",
      "|     20     |     17    |     15    |   2    |    0    |\n",
      "+------------+-----------+-----------+--------+---------+\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'DT_Classifier': {'args': {'ALGORITHM': 1, 'MAX_DEPTH': 3, 'MIN_RECORDS_OF_PARENT': 7, 'MIN_RECORDS_OF_LEAF': 19}, 'inputs': {'data': {'FS_supervised': {'args': {'FS_METHOD': 13, 'TOP_K_BEST': 10}, 'inputs': {'data': {'SMOTETomek': {'args': {'K_NEAREST_NEIGHBOURS': 3, 'METHOD': 1, 'SAMPLING_STRATEGY': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'HGBT_Classifier': {'args': {'ITER_NUM': 100, 'MAX_DEPTH': 10, 'ETA': 0.1, 'NODE_SIZE': 4}, 'inputs': {'data': 'ROWDATA'}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'RDT_Classifier': {'args': {'TREES_NUM': 100, 'NODE_SIZE': 4, 'CALCULATE_OOB': 0, 'SAMPLE_FRACTION': 1.0}, 'inputs': {'data': {'PolynomialFeatures': {'args': {'MIN_DEGREE': 1, 'MAX_DEGREE': 2, 'INTERACTION_ONLY': False, 'INCLUDE_BIAS': False}, 'inputs': {'data': {'FS_supervised': {'args': {'FS_METHOD': 12, 'TOP_K_BEST': 10}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'RDT_Classifier': {'args': {'TREES_NUM': 100, 'NODE_SIZE': 16, 'CALCULATE_OOB': 0, 'SAMPLE_FRACTION': 0.75}, 'inputs': {'data': {'PolynomialFeatures': {'args': {'MIN_DEGREE': 1, 'MAX_DEGREE': 2, 'INTERACTION_ONLY': False, 'INCLUDE_BIAS': False}, 'inputs': {'data': {'OneHotEncoder': {'args': {'MINIMUM_FRACTION': 0.05, 'IGNORE_UNKNOWN': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[34mEvaluating \u001b[39m{'SVM_Classifier': {'args': {'TYPE': 1, 'KERNEL_TYPE': 0, 'ERROR_TOL': 0.01, 'SCALE_INFO': 1, 'SHRINK': 0}, 'inputs': {'data': {'SMOTE': {'args': {'K_NEAREST_NEIGHBOURS': 1, 'METHOD': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'M_LOGR_Classifier': {'args': {'MAX_ITERATION': 100, 'ENET_ALPHA': 1.0, 'ENET_LAMBDA': 0.001}, 'inputs': {'data': {'CATPCA': {'args': {'COMPONENTS_PERCENTAGE': 0.1, 'SCALING': 1, 'COMPONENT_TOL': 0.0, 'MAX_ITERATION': 1000, 'CONVERGE_TOL': 1e-05, 'LANCZOS_ITERATION': 1000, 'SVD_CALCULATOR': 0}, 'inputs': {'data': 'ROWDATA'}}}}}}\n",
      "\u001b[34mEvaluating \u001b[39m{'MLP_Classifier': {'args': {'ACTIVATION': 13, 'OUTPUT_ACTIVATION': 13, 'HIDDEN_LAYER_SIZE': '100', 'FUNCTIONALITY': 0, 'LEARNING_RATE': 0.5, 'MOMENTUM': 0.9, 'TRAINING_STYLE': 1, 'WEIGHT_INIT': 0, 'NORMALIZATION': 0}, 'inputs': {'data': {'FS_supervised': {'args': {'FS_METHOD': 13, 'TOP_K_BEST': 10}, 'inputs': {'data': {'PolynomialFeatures': {'args': {'MIN_DEGREE': 1, 'MAX_DEGREE': 2, 'INTERACTION_ONLY': False, 'INCLUDE_BIAS': False}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[31mEvaluated(failed) \u001b[39m{'MLP_Classifier': {'args': {'ACTIVATION': 13, 'OUTPUT_ACTIVATION': 13, 'HIDDEN_LAYER_SIZE': '100', 'FUNCTIONALITY': 0, 'TRAINING_STYLE': 0, 'WEIGHT_INIT': 0, 'NORMALIZATION': 0}, 'inputs': {'data': {'OneHotEncoder': {'args': {'MINIMUM_FRACTION': 0.2, 'IGNORE_UNKNOWN': 1}, 'inputs': {'data': {'SCALE': {'args': {'SCALING_METHOD': 2}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'M_LOGR_Classifier': {'args': {'MAX_ITERATION': 100, 'ENET_ALPHA': 1.0, 'ENET_LAMBDA': 0.01}, 'inputs': {'data': {'FS_unsupervised': {'args': {'FS_METHOD': 9, 'FS_SIGMA': 10.0, 'TOP_K_BEST': 10}, 'inputs': {'data': {'SMOTETomek': {'args': {'K_NEAREST_NEIGHBOURS': 1, 'METHOD': 1, 'SAMPLING_STRATEGY': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'RDT_Classifier': {'args': {'TREES_NUM': 100, 'NODE_SIZE': 8, 'CALCULATE_OOB': 0, 'SAMPLE_FRACTION': 0.75}, 'inputs': {'data': {'SMOTETomek': {'args': {'K_NEAREST_NEIGHBOURS': 3, 'METHOD': 1, 'SAMPLING_STRATEGY': 2}, 'inputs': {'data': 'ROWDATA'}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'NB_Classifier': {'args': {'LAPLACE': 0.01}, 'inputs': {'data': {'TomekLinks': {'args': {'SAMPLING_STRATEGY': 2, 'DISTANCE_LEVEL': 2, 'METHOD': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'NB_Classifier': {'args': {'LAPLACE': 1.0}, 'inputs': {'data': {'FS_supervised': {'args': {'FS_METHOD': 5, 'TOP_K_BEST': 10}, 'inputs': {'data': {'SAMPLING': {'args': {'SAMPLING_METHOD': 6, 'PERCENTAGE': 0.7999999999999999}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'DT_Classifier': {'args': {'ALGORITHM': 3, 'MAX_DEPTH': 1, 'MIN_RECORDS_OF_PARENT': 4, 'MIN_RECORDS_OF_LEAF': 16}, 'inputs': {'data': {'FS_unsupervised': {'args': {'FS_METHOD': 9, 'FS_SIGMA': 10.0, 'TOP_K_BEST': 10}, 'inputs': {'data': {'LabelEncoder': {'args': {'IGNORE_UNKNOWN': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'HGBT_Classifier': {'args': {'ITER_NUM': 100, 'MAX_DEPTH': 1, 'ETA': 0.001, 'NODE_SIZE': 14}, 'inputs': {'data': 'ROWDATA'}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'SVM_Classifier': {'args': {'TYPE': 1, 'KERNEL_TYPE': 0, 'ERROR_TOL': 0.1, 'SCALE_INFO': 1, 'SHRINK': 1}, 'inputs': {'data': {'LabelEncoder': {'args': {'IGNORE_UNKNOWN': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}\n",
      "\u001b[34mEvaluating \u001b[39m{'SVM_Classifier': {'args': {'TYPE': 1, 'KERNEL_TYPE': 0, 'ERROR_TOL': 0.1, 'SCALE_INFO': 0, 'SHRINK': 0}, 'inputs': {'data': {'OneHotEncoder': {'args': {'MINIMUM_FRACTION': 0.25, 'IGNORE_UNKNOWN': 1}, 'inputs': {'data': {'FS_unsupervised': {'args': {'FS_METHOD': 10, 'FS_SIGMA': 1.0, 'TOP_K_BEST': 10}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'M_LOGR_Classifier': {'args': {'MAX_ITERATION': 100, 'ENET_ALPHA': 0.0, 'ENET_LAMBDA': 10.0}, 'inputs': {'data': {'OneHotEncoder': {'args': {'MINIMUM_FRACTION': 0.2, 'IGNORE_UNKNOWN': 1}, 'inputs': {'data': {'FS_unsupervised': {'args': {'FS_METHOD': 9, 'FS_SIGMA': 100.0, 'TOP_K_BEST': 10}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[31mEvaluated(failed) \u001b[39m{'SVM_Classifier': {'args': {'TYPE': 1, 'KERNEL_TYPE': 0, 'ERROR_TOL': 0.01, 'SCALE_INFO': 0, 'SHRINK': 0}, 'inputs': {'data': {'SCALE': {'args': {'NEW_MIN': 4.0, 'SCALING_METHOD': 0, 'NEW_MAX': 6.0}, 'inputs': {'data': {'SAMPLING': {'args': {'SAMPLING_METHOD': 5, 'PERCENTAGE': 0.30000000000000004}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'RDT_Classifier': {'args': {'TREES_NUM': 100, 'NODE_SIZE': 3, 'CALCULATE_OOB': 0, 'SAMPLE_FRACTION': 0.75}, 'inputs': {'data': {'SAMPLING': {'args': {'SAMPLING_METHOD': 0, 'PERCENTAGE': 0.8999999999999999}, 'inputs': {'data': 'ROWDATA'}}}}}}\n",
      "\u001b[32mEvaluated(succeeded) \u001b[39m{'SVM_Classifier': {'args': {'TYPE': 1, 'KERNEL_TYPE': 0, 'ERROR_TOL': 0.1, 'SCALE_INFO': 1, 'SHRINK': 1}, 'inputs': {'data': {'FS_supervised': {'args': {'FS_METHOD': 2, 'TOP_K_BEST': 10}, 'inputs': {'data': {'TomekLinks': {'args': {'SAMPLING_STRATEGY': 3, 'DISTANCE_LEVEL': 2, 'METHOD': 1}, 'inputs': {'data': 'ROWDATA'}}}}}}}}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\I308290\\AppData\\Local\\miniconda3\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\visualizers\\automl_progress.py\", line 546, in run\n",
      "    self.fetch()\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\visualizers\\automl_progress.py\", line 503, in fetch\n",
      "ERROR:hana_ml.algorithms.pal.auto_ml:(-10807, \"Connection down: [89006] System call 'recv' failed, rc=10054:远程主机强迫关闭了一个现有的连接。 {0.0.0.0:60056 -> 10.237.43.114:31315 TenantName:(none) SiteVolumeID:0:2 SiteType:NONE ConnectionID:208429 SessionID:1034884207529778}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\algorithms\\pal\\auto_ml.py\", line 781, in _fit\n",
      "    self._call_pal_auto(conn,\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\algorithms\\pal\\pal_base.py\", line 892, in _call_pal_auto\n",
      "    self.execute_statement, materialize_dict = call_pal_auto_with_hint(conn_context,\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\algorithms\\pal\\pal_base.py\", line 1408, in call_pal_auto_with_hint\n",
      "    if try_exec(cur, sql, conn):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\algorithms\\pal\\pal_base.py\", line 1363, in try_exec\n",
      "    cur.execute(sql)\n",
      "hdbcli.dbapi.Error: (-10807, \"Connection down: [89006] System call 'recv' failed, rc=10054:远程主机强迫关闭了一个现有的连接。 {0.0.0.0:60056 -> 10.237.43.114:31315 TenantName:(none) SiteVolumeID:0:2 SiteType:NONE ConnectionID:208429 SessionID:1034884207529778}\")\n",
      "    self.do_fetch(self.simplified_columns)\n",
      "  File \"c:\\users\\i308290\\hanamlapi\\src\\hana_ml\\visualizers\\automl_progress.py\", line 479, in do_fetch\n",
      "    self.connection_cursor.execute(sql)\n",
      "hdbcli.dbapi.Error: (-10807, \"Connection down: [89006] System call 'recv' failed, rc=10053:你的主机中的软件中止了一个已建立的连接。 {0.0.0.0:60214 -> 10.237.43.114:31315 TenantName:(none) SiteVolumeID:0:2 SiteType:NONE ConnectionID:208432 SessionID:1034901578133226}\")\n"
     ]
    }
   ],
   "source": [
    "from timeit import time\n",
    "import json\n",
    "from hana_ml.algorithms.pal.auto_ml import AutomaticClassification\n",
    "from hana_ml.visualizers.automl_progress import PipelineProgressStatusMonitor\n",
    "\n",
    "for case in classification_df:\n",
    "    dataframe.create_dataframe_from_pandas(connection_context, case[\"pandas\"], table_name=case[\"file_name\"], force=True)\n",
    "    hana_df = connection_context.table(case[\"file_name\"])\n",
    "    start_time = time.time()\n",
    "    auto_c = AutomaticClassification(connections='default')\n",
    "    auto_c.disable_workload_class_check()\n",
    "    progress_status_monitor = PipelineProgressStatusMonitor(connection_context=connection_context,\n",
    "                                                            automatic_obj=auto_c,\n",
    "                                                            runtime_platform='console')\n",
    "    progress_status_monitor.start()\n",
    "    auto_c.fit(hana_df, key=case[\"key\"], label=case[\"label\"])\n",
    "    result = {\n",
    "        \"file_name\": case[\"file_name\"],\n",
    "        \"metrics\": json.loads(auto_c.best_pipeline_.SCORES.collect().iat[0,0]),\n",
    "        \"runtime\": time.time() - start_time\n",
    "    }\n",
    "    print(result)\n",
    "    with open('hana_{}_result.pkl'.format(case[\"file_name\"]), 'wb') as f:  # open a text file\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41605ad-125b-47e5-959f-4efd7cdff8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import time\n",
    "import json\n",
    "from hana_ml.algorithms.pal.auto_ml import AutomaticRegression\n",
    "from hana_ml.visualizers.automl_progress import PipelineProgressStatusMonitor\n",
    "for case in regression_df:\n",
    "    if not connection_context.has_table(case[\"file_name\"]):\n",
    "        dataframe.create_dataframe_from_pandas(connection_context, case[\"pandas\"], table_name=case[\"file_name\"])\n",
    "    hana_df = connection_context.table(case[\"file_name\"])\n",
    "    start_time = time.time()\n",
    "    auto_r = AutomaticRegression(connections='default')\n",
    "    auto_r.disable_workload_class_check()\n",
    "    progress_status_monitor = PipelineProgressStatusMonitor(connection_context=connection_context,\n",
    "                                                            automatic_obj=auto_r,\n",
    "                                                            runtime_platform='console')\n",
    "    progress_status_monitor.start()\n",
    "    auto_r.fit(hana_df, key=case[\"key\"], label=case[\"label\"])\n",
    "    result = {\n",
    "        \"file_name\": case[\"file_name\"],\n",
    "        \"metrics\": json.loads(auto_r.best_pipeline_.SCORES.collect().iat[0,0]),\n",
    "        \"runtime\": time.time() - start_time\n",
    "    }\n",
    "    print(result)\n",
    "    with open('hana_{}_result.pkl'.format(case[\"file_name\"]), 'wb') as f:  # open a text file\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d947f6a-16ee-4e74-ae5d-51c6b628fff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c71697-c3cc-45c5-afb0-a7580635369b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
